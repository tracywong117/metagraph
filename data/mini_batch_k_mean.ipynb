{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import faiss\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60801408, 32)\n",
      "(60801408, 4)\n"
     ]
    }
   ],
   "source": [
    "anno_files_list = get_all_anno_files(\".\")\n",
    "anno_bit_vectors = load_all_annotation_bit_vectors(anno_files_list).T\n",
    "print(anno_bit_vectors.shape) # [rows, cols]\n",
    "packed_anno_bit_vectors = np.packbits(anno_bit_vectors, axis=1)\n",
    "packed_anno_bit_vectors = np.ascontiguousarray(packed_anno_bit_vectors)\n",
    "print(packed_anno_bit_vectors.shape) # [rows, cols/8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [07:45<00:04,  4.72s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def compute_centroid(cluster):\n",
    "    \"\"\"\n",
    "    Compute the centroid (bitwise majority) of a cluster of dim-bit binary codes (dim/8 uint8).\n",
    "    \n",
    "    Args:\n",
    "        cluster (list of np.ndarray): List of (dim/8,) binary codes as `uint8` arrays.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Centroid as a (dim/8,) `uint8` array.\n",
    "    \"\"\"\n",
    "    if not cluster:\n",
    "        return None\n",
    "    \n",
    "    # Convert cluster to a 2D numpy array (each row is a uint8 array)\n",
    "    cluster_bits = np.array(cluster, dtype=np.uint8)\n",
    "    \n",
    "    # Compute bitwise majority for each bit in the uint8 arrays\n",
    "    # First, count the number of 1s per bit position\n",
    "    # Since each uint8 has 8 bits, we need to count these bitwise\n",
    "    majority_bits = np.zeros_like(cluster_bits[0], dtype=np.uint8)\n",
    "    for i in range(8):  # Iterate over all 8 bits in each uint8\n",
    "        bit_counts = (cluster_bits >> i) & 1  # Isolate the i-th bit for all elements\n",
    "        majority_bit = (bit_counts.sum(axis=0) >= (len(cluster) / 2)).astype(np.uint8)  # Majority vote\n",
    "        majority_bits |= (majority_bit << i)  # Set the i-th bit in the centroid\n",
    "    \n",
    "    return majority_bits\n",
    "\n",
    "\n",
    "def compute_hamming_distances(args):\n",
    "    \"\"\"\n",
    "    Compute the Hamming distances between a point and all centroids.\n",
    "    \n",
    "    Args:\n",
    "        args (tuple): (point, centroids)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (point, index of closest centroid, distance to closest centroid)\n",
    "    \"\"\"\n",
    "    point, centroids = args\n",
    "    distances = hamming_distances_1_to_n(point, np.array(centroids))\n",
    "    cluster_idx = np.argmin(distances)\n",
    "    return point, cluster_idx\n",
    "\n",
    "def hamming_distances_1_to_n(point, array):\n",
    "    \"\"\"\n",
    "    point: numpy array of uint8 (dim/8)\n",
    "    array: numpy array of uint8 (m, dim/8)\n",
    "    \n",
    "    return: numpy array of uint8 (m)\n",
    "    \"\"\"\n",
    "    return np.unpackbits(np.bitwise_xor(point, array), axis=1).sum(axis=1)\n",
    "\n",
    "\n",
    "def mini_batch_kmeans_hamming(dataset, k, batch_size=1000, max_iters=10):\n",
    "    \"\"\"\n",
    "    Perform Mini-Batch K-means clustering using Hamming distance for 64-bit binary codes.\n",
    "    \n",
    "    Args:\n",
    "        dataset (list of int): List of 64-bit binary codes as integers.\n",
    "        k (int): Number of clusters.\n",
    "        batch_size (int): Size of each mini-batch.\n",
    "        max_iters (int): Maximum number of iterations.\n",
    "        \n",
    "    Returns:\n",
    "        list: Cluster assignments for each data point.\n",
    "        list: Final centroids for each cluster.\n",
    "    \"\"\"\n",
    "    n = len(dataset)\n",
    "    \n",
    "    # Step 1: Initialize centroids (randomly select k points from the dataset)\n",
    "    # dataset is (n, dim/8)\n",
    "    # random select k points from the dataset\n",
    "    rng = np.random.default_rng()\n",
    "    centroids = rng.choice(dataset, k, replace=False)\n",
    "    \n",
    "    # Initialize cluster assignments\n",
    "    cluster_assignments = [None] * n\n",
    "    cluster_counts = [0] * k  # Track number of points assigned to each cluster\n",
    "    print(\"Initialization complete.\")\n",
    "    \n",
    "    # Step 2: Iterate until convergence or max iterations\n",
    "    for iteration in tqdm(range(max_iters)):\n",
    "        # Step 2.1: Sample a mini-batch from the dataset\n",
    "        mini_batch = dataset[rng.choice(n, batch_size, replace=False)]\n",
    "        \n",
    "        # Step 2.2: Assign points in the mini-batch to the nearest centroid\n",
    "        clusters = [[] for _ in range(k)]\n",
    "        \n",
    "        # Use multiprocessing to compute distances in parallel\n",
    "        with Pool(cpu_count()) as pool:\n",
    "            results = list(pool.imap(compute_hamming_distances, [(point, centroids) for point in mini_batch]))\n",
    "        # Single-threaded version\n",
    "        # results = [compute_hamming_distances((point, centroids)) for point in mini_batch]\n",
    "        \n",
    "        # Update cluster assignments and counts based on mini-batch results\n",
    "        for point, cluster_idx in results:\n",
    "            clusters[cluster_idx].append(point)\n",
    "            cluster_counts[cluster_idx] += 1\n",
    "        \n",
    "        # Step 2.3: Update centroids incrementally using the mini-batch\n",
    "        new_centroids = centroids.copy()\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            if cluster:\n",
    "                cluster_centroid = compute_centroid(cluster)\n",
    "                \n",
    "                # Incrementally update centroid using a weighted average\n",
    "                if cluster_counts[cluster_idx] > 0:\n",
    "                    new_centroids[cluster_idx] = (\n",
    "                        (cluster_counts[cluster_idx] - len(cluster)) * centroids[cluster_idx] + cluster_centroid\n",
    "                    ) // cluster_counts[cluster_idx]\n",
    "        \n",
    "        # Check for convergence (if centroids do not change)\n",
    "        if np.array_equal(centroids, new_centroids):\n",
    "            print(\"Convergence reached.\")\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    # Final assignment: Assign all points in the dataset to the nearest centroid\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        final_results = list(tqdm(pool.imap(compute_hamming_distances, [(point, centroids) for point in dataset]), total=n))\n",
    "    \n",
    "    for i, (point, cluster_idx) in enumerate(final_results):\n",
    "        cluster_assignments[i] = cluster_idx  # Assign cluster index directly by position\n",
    "        \n",
    "    return cluster_assignments, centroids\n",
    "\n",
    "\n",
    "# Perform Mini-Batch K-means clustering\n",
    "cluster_assignments, centroids = mini_batch_kmeans_hamming(packed_anno_bit_vectors, k=50000, batch_size=10000, max_iters=100)\n",
    "# Save the cluster assignments and centroids\n",
    "np.save(\"cluster_assignments.npy\", np.array(cluster_assignments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(3, 2)\n",
      "[16  8 10]\n"
     ]
    }
   ],
   "source": [
    "def hamming_distances(x, y):\n",
    "    \"\"\"\n",
    "    x: numpy array of uint8 (dim/8)\n",
    "    y: numpy array of uint8 (m, dim/8)\n",
    "    \n",
    "    return: numpy array of uint8 (m)\n",
    "    \"\"\"\n",
    "    return np.unpackbits(np.bitwise_xor(x, y), axis=1).sum(axis=1)\n",
    "\n",
    "# Example usage of hammind_distances\n",
    "x = np.array([0b00000000, 0b11111111], dtype=np.uint8)\n",
    "y = np.array([[0b11111111, 0b00000000], [0b11001100, 0b00110011], [0b11001111, 0b00110011]], dtype=np.uint8)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(hamming_distances(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171  85]\n",
      "10101011\n",
      "01010101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_centroid(cluster):\n",
    "    \"\"\"\n",
    "    Compute the centroid (bitwise majority) of a cluster of dim-bit binary codes (dim/8 uint8).\n",
    "    \n",
    "    Args:\n",
    "        cluster (list of np.ndarray): List of (dim/8,) binary codes as `uint8` arrays.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Centroid as a (dim/8,) `uint8` array.\n",
    "    \"\"\"\n",
    "    if not cluster:\n",
    "        return None\n",
    "    \n",
    "    # Convert cluster to a 2D numpy array (each row is a uint8 array)\n",
    "    cluster_bits = np.array(cluster, dtype=np.uint8)\n",
    "    \n",
    "    # Compute bitwise majority for each bit in the uint8 arrays\n",
    "    # First, count the number of 1s per bit position\n",
    "    # Since each uint8 has 8 bits, we need to count these bitwise\n",
    "    majority_bits = np.zeros_like(cluster_bits[0], dtype=np.uint8)\n",
    "    for i in range(8):  # Iterate over all 8 bits in each uint8\n",
    "        bit_counts = (cluster_bits >> i) & 1  # Isolate the i-th bit for all elements\n",
    "        majority_bit = (bit_counts.sum(axis=0) >= (len(cluster) / 2)).astype(np.uint8)  # Majority vote\n",
    "        majority_bits |= (majority_bit << i)  # Set the i-th bit in the centroid\n",
    "    \n",
    "    return majority_bits\n",
    "\n",
    "\n",
    "# Example usage of compute_centroid\n",
    "cluster = [\n",
    "    np.array([0b10101010, 0b01010101], dtype=np.uint8),\n",
    "    np.array([0b10101010, 0b01010101], dtype=np.uint8),\n",
    "    np.array([0b00000001, 0b11111111], dtype=np.uint8),\n",
    "    np.array([0b01111111, 0b00000000], dtype=np.uint8),\n",
    "]\n",
    "\n",
    "print(compute_centroid(cluster))  # Expected output: [0b10101010, 0b01010101]\n",
    "# print as binary\n",
    "print(f\"{compute_centroid(cluster)[0]:08b}\")\n",
    "print(f\"{compute_centroid(cluster)[1]:08b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0b01010101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgdb-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
